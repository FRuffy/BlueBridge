%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related work}
\label{sec:related}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Popular tools for collecting and analyzing console logs include
%% fluentd~\cite{fluentd}, logstash~\cite{logstash},
%% graylog~\cite{graylog}, splunk~\cite{splunk},
%% papertrail~\cite{papertrailapp}, loggly~\cite{loggly}, and
%% sumologic~\cite{sumologic}.

Distributed system state has a long
history~\cite{dist_snapshots_Chandy1985,
  state_machine_replication_Schneider1990,
  geels_friday_nsdi_2007}. Prior work uses concrete state of a system
to check the system against known properties~\cite{yang_modist_nsdi09,
  killian_macemc_nsdi_2007}. To be more immediately useful to
developers who are attempting to understand complex systems, we think
that distributed state requires abstraction. Dinv is one way to
achieve this abstraction.

\textbf{Mining distributed systems information.}
%
At its core DInv is a tool to mine information about a distributed system.
%% tackles the problem of mining and abstracting distributed state.
Other work in this domain detects
dependencies~\cite{lou_mining_distsys_deps_osr_2010}, temporal
properties~\cite{Beschastnikh2012},
anomalies~\cite{xu_console_log_mining_sosp_2009}, and performance
bugs~\cite{Sambasivan11}. However, this prior work focuses on events,
and not state. The closest prior work in the sequential domain is
Daikon~\cite{Ernst07}, which cannot be applied to distributed systems.

Yabandeh et al.~\cite{yabandeh_avenger_srds_2011} infer
almost-invariants in distributed systems: invariants that are true in
most cases and assume these invariants only are violated due to
bugs. They require the user to provide a list of variables and
functions for invariant inference. DInv can infer distributed state
variables automatically. They also assume that an external module
generates a trace of globally consistent cuts with distributed state
for their algorithm; our approach actually instruments the system and
generates these consistent cuts.

%% Temporal invariants in distributed systems have been automatically
%% inferred by mining partially ordered logs
%% Finite state machines, and communication finite state machines can be
%% automatically detected using similar
%% processes~\cite{Beschastnikh13}~\cite{Beschastnikh14}. Both approaches
%% require minimal instrumentation and summarize useful state information
%% for developers.  These high level approaches do not attempt to detect
%% data properties.

%% Distributed system analysis is a rich field with many contributions
%% aimed at profiling distributed system behaviour.


\textbf{Other analysis of distributed systems.} Dynamic analysis of
distributed systems has yielded a number of tools to aid
developers. Googles Dapper~\cite{Dapper} analyzes traces of
distributed systems to produce call graphs and report performance
information. 
%% The system is widely used at Google and has been credited
%% with large scale improvements to AdWords. Dapper does not focus on
%% distribute state.
%
%% Dapper is not fully automated and requires developers to
%% manually annotate source code to produce trace files.
%
Another profiling tool, \textit{lprof}, developed by Zhao et
al.~\cite{Zhao:2014:LNR:2685048.2685099} automatically instruments
Java bytecode by injecting information method information into
existing log statements. Based on the generated execution logs lprof
builds a call graph and infers temporal properties about the
log. Lprof's instrumentation relies on synchronized timestamps rather
then vector clocks, which limits its applicability to distributed
systems.
%% generality of the system. Both approaches have proven useful as
%% debugging aids, and for identifying latency issues.

%% There have been prior efforts to automatically instrument networked
%% systems, and derive their invariants using
%% Daikon. InvarScope~\cite{groeneveld2010automatic} detects invariants
%% in JavaScript applications. 
%% %% Their technique involves capturing HTTP request and instrumenting
%% %% them on the fly. They then profile an entire site by merging the
%% %% invariants found on a large set of runs.
%% This approach is localized to client-side code, and does not
%% generalize beyond client-server systems.
% detect global invariants between the client and server.

%% Real time monitoring of distributed systems is classically hard due to
%% variances in network topologies, and correlation between events on
%% various machines.
%% Dtrace~\cite{Cantrill04dynamicinstrumentation}, and
Monitoring systems such as Fay~\cite{Fay2011} and Pivot
tracing~\cite{Mace2015} use dynamic instrumentation for real-time
diagnosis of distributed systems by activating trace points at
runtime. %% Unfortunately correlating events
%% using these programs is still a complex developer task. Pivot
%% tracing
%~\cite{Mace2015} addresses this problem by introducing a
%% happens-before join which enables trace queries to be contextualized
%% by Lamport's happened-before relation. All these approaches have the
%% advantage of introducing minimal overhead to running systems while
%% providing diagnostic information. 
%% The processing of information generated by the traces is a task left
%% to developers. 
These tools do not infer properties, such as invariants, that are
present in the traces they capture.

\textbf{Formal methods for distributed systems.}  %% Although recent
%% experiences from Amazon~\cite{newcombe_tla_cacm15} indicate that there
%% is utility in modeling existing implementations,
%% We assume that developers want to check their implementations, not a
%% formal model, which is also difficult to create.
%
Unlike recent methods that use theorem proving to synthesize correct
systems by construction~\cite{wilcox_verdi_pldi15,
  hawblitzel_ironfleet_sosp2015}, our work is immediately applicable
to existing production systems. %, specifically those written in Go.
%
Previous work also considers checking existing system implementations
directly~\cite{yang_modist_nsdi09, killian_macemc_nsdi_2007}, or
checking system properties at runtime or during program
replay~\cite{reynolds_pip_2006,
  geels_friday_nsdi_2007,liu_d3s_nsdi_2008,VeriFlow}.  This work
assumes that a developer can, and is willing to, specify properties of
their system. By contrast, Dinv does not require the developer to
formally specify their system and aims at elucidating the runtime
properties of the system.

%% However, the catch is that the developer must be willing to and is
%% sufficiently familiar with their system to interpret \emph{likely
%%   specifications} that we infer for their system.

%% Notable progress has been made in summarizing specifications via
%% symbolic message sequence graphs to group machines into classes based
%% on similarities in their communication patterns~\cite{Kumar2012}. This
%% process is out of the scope of our work but could be leveraged to
%% yield more specific invariant inference.

%% \todo{Other papers to cite:
%% Avenger SRDS,
%% \url{http://arxiv.org/pdf/1604.04638.pdf}
%% \url{http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7381842}
%% }
